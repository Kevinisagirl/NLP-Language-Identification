{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from itertools import islice\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that will read in a list of characters\n",
    "# and convert into lists of letter, next letter\n",
    "def window(seq, n=2):\n",
    "    it = iter(seq)\n",
    "    result = tuple(islice(it, n))\n",
    "    if len(result) == n:\n",
    "        yield result\n",
    "    for elem in it:\n",
    "        result = result[1:] + (elem,)\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a function that takes in a list of characters and\n",
    "# calculates the bayesian unigram prior smoothing probabilites\n",
    "# count of bigram + prob(second char) / count(first char) + 1\n",
    "def bayesian_unigram_prior_smoothing_prob(char_list, lang):\n",
    "        # character frequencies\n",
    "        chars = pd.DataFrame(char_list, columns=['character'])\n",
    "        char_freqs = chars.character.value_counts().reset_index(name='counts')\n",
    "        char_probs = chars.character.value_counts(normalize=True).reset_index(name='state2_prob')\n",
    "        # rename some columns for easy merge later\n",
    "        char_freqs.columns = ['state1', 'state1_count']\n",
    "        char_probs.columns = ['state2', 'state2_prob']\n",
    "        \n",
    "        # create bigrams\n",
    "        pairs = pd.DataFrame(window(char_list), columns=['state1', 'state2'])\n",
    "        # bigram frequencies\n",
    "        bigrams = pairs.groupby(['state1','state2']).size().reset_index(name='bigram_count')\n",
    "        \n",
    "        # pull in the first char counts and second char probs from above\n",
    "        bigrams = pd.merge(bigrams, char_probs, on='state2')\n",
    "        bigrams = pd.merge(bigrams, char_freqs, on='state1')\n",
    "        \n",
    "        # calculate the bigram smoothed probs\n",
    "        bigrams['p_smooth'] = (bigrams.bigram_count + bigrams.state2_prob)/(bigrams.state1_count + 1)\n",
    "        \n",
    "        # convert to log prob\n",
    "        # use a name specific to language\n",
    "        col_name = lang+'_log_p_smooth'\n",
    "        bigrams[col_name] = np.log(bigrams.p_smooth)\n",
    "        \n",
    "        # keep only required columns\n",
    "        bigrams = bigrams[['state1', 'state2', col_name]].copy()\n",
    "        print(bigrams.head())\n",
    "        \n",
    "        return(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in dut file: 2498\n",
      "  state1   state2  dut_log_p_smooth\n",
      "0     \\n       \\n         -3.648464\n",
      "1     \\n        \f",
      "         -3.663161\n",
      "2     \\n  <<END>>         -3.663161\n",
      "3     \\n        N         -3.659566\n",
      "4     \\n        O         -1.583670\n",
      "Number of characters in eng file: 2044\n",
      "  state1   state2  eng_log_p_smooth\n",
      "0     \\n       \\n         -3.538851\n",
      "1     \\n        \f",
      "         -3.554859\n",
      "2     \\n  <<END>>         -3.554859\n",
      "3     \\n        N         -3.553881\n",
      "4     \\n        P         -2.861712\n",
      "Number of characters in esper file: 2044\n",
      "  state1   state2  esper_log_p_smooth\n",
      "0     \\n       \\n           -3.538851\n",
      "1     \\n        \f",
      "           -3.554859\n",
      "2     \\n  <<END>>           -3.554859\n",
      "3     \\n        A           -2.860979\n",
      "4     \\n        L           -3.554859\n",
      "Number of characters in frn file: 2275\n",
      "  state1   state2  frn_log_p_smooth\n",
      "0     \\n       \\n         -2.507045\n",
      "1     \\n        \f",
      "         -3.610478\n",
      "2     \\n  <<END>>         -3.610478\n",
      "3     \\n        C         -1.664506\n",
      "4     \\n        L         -3.610478\n",
      "Number of characters in ger file: 2231\n",
      "  state1   state2  ger_log_p_smooth\n",
      "0     \\n       \\n         -3.594910\n",
      "1     \\n  <<END>>         -3.610470\n",
      "2     \\n        A         -3.606446\n",
      "3     \\n        D         -3.610022\n",
      "4     \\n        G         -2.223280\n",
      "Number of characters in spn file: 2356\n",
      "  state1   state2  spn_log_p_smooth\n",
      "0     \\n       \\n         -3.647561\n",
      "1     \\n        \f",
      "         -3.663137\n",
      "2     \\n        1         -3.662289\n",
      "3     \\n  <<END>>         -3.663137\n",
      "4     \\n        A         -3.661865\n"
     ]
    }
   ],
   "source": [
    "# for each language file we'll calculate the log bayesian unigram prior smoothing probability\n",
    "training_probs = {}\n",
    "for dq_file in glob.glob('train/*.txt'):\n",
    "    # create new file name to save transition matrix\n",
    "    language = dq_file.split(\".\")[0][6:]\n",
    "    character_list = [\"<<START>>\"]\n",
    "    with open(dq_file, 'r') as dq_text:\n",
    "        for line in dq_text:\n",
    "            # convert each line into a list of characters\n",
    "            line_character_list = list(line)\n",
    "            # add the characters of the line to the list of characters for the whole text\n",
    "            character_list += line_character_list\n",
    "        # add end character\n",
    "        character_list.append(\"<<END>>\")\n",
    "        print(\"Number of characters in\", language, \"file:\", len(character_list))\n",
    "        prob_df = bayesian_unigram_prior_smoothing_prob(character_list,language)\n",
    "        training_probs[language] = prob_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev File Language : Predicted Language\n",
      "dut : dut\n",
      "eng : eng\n",
      "esper : spn\n",
      "frn : frn\n",
      "ger : ger\n",
      "spn : spn\n"
     ]
    }
   ],
   "source": [
    "# Now that we have the training log probabilities, we can attempt\n",
    "# to determine the languages of the test documents\n",
    "print(\"Dev File Language : Predicted Language\")\n",
    "for dq_file in glob.glob('dev/*.txt'):\n",
    "    language = dq_file.split(\".\")[0][4:]\n",
    "    character_list = [\"<<START>>\"]\n",
    "    with open(dq_file, 'r') as dq_text:\n",
    "        for line in dq_text:\n",
    "            # convert each line into a list of characters\n",
    "            line_character_list = list(line)\n",
    "            # add the characters of the line to the list of characters for the whole text\n",
    "            character_list += line_character_list\n",
    "        # add end character\n",
    "        character_list.append(\"<<END>>\")\n",
    "    test_bigrams = pd.DataFrame(window(character_list), columns=['state1', 'state2'])\n",
    "\n",
    "    # grab the log probabilites for each language\n",
    "    for l, probs in training_probs.items():\n",
    "        test_bigrams = pd.merge(test_bigrams, probs, on=['state1','state2'])\n",
    "    \n",
    "    highest_log_prob = test_bigrams.iloc[:,2:].sum().reset_index().set_index('index').idxmax().values[0]\n",
    "    print(language, \":\", highest_log_prob.split(\"_\")[0])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty good.. not perfect."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
